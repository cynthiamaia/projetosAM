{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AM_parteII_Missao_08_comites.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2mbYWpX_iz7x"},"source":["#**Atividade de Aprendizagem de Máquina - Missão 8**"]},{"cell_type":"markdown","metadata":{"id":"uEJFGVQ_i4RR"},"source":["Discentes:  Cynthia Moreira Maia, Lucas Benevides Viana de Amorim e Sara Bandeira Coutinho\n","\n","Docente: Dr. Leandro Maciel Almeida"]},{"cell_type":"markdown","metadata":{"id":"GiBGaaQIih0x"},"source":["**Atividade:** Realizar experimento com a implementação de comitês bagging, boosting e stacking para base de dados do Glass. Os modelos base para formação do comitê poderão ser KNN, SVM, Árvore de Decisão e/ou Redes Neurais Artificiais. Realizar uma busca de tal modo que os comitês apresentem desempenho superior ao desempenho solo dos classificadores. Apresentar análise, os principais desafios encontrados para a construção dos comitês e conclusões."]},{"cell_type":"markdown","metadata":{"id":"8_JDV7E17e8z"},"source":["###**Introdução**\n","\n","Os comitês de classificadores são sistemas de classificação compostos por um conjunto de classificadores e por um método responsável pela combinação dos resultados. Os comitês têm como objetivo melhorar o desempenho na classificação dos dados, por meio da integração dos resultados dos classificadores para que ao final se tenha um resultado final mais acurado [1]. O método de combinação reune os resultados dos classificadores base em uma resposta final que corresponde à saída do comitê [2]. De acordo com Kuncheva (2004) [1], os métodos de combinação podem ser categorizados em duas estratégias principais: fusão e seleção. São exemplos de métodos de seleção, o comitê Bagging [3] e Boosting [4], que são métodos com preditores homogêneos. No Bagging, é feito com os preditores homogêneos de forma independente e paralela em relação ao outro. O resultado final, é de acordo com o resultado médio do que foi obtido a partir dos preditores. No Boosting, os preditores são aplicados de forma sequencial, no qual, o posterior depende do antecessor e depois são combinados no modelo final [5].\n","\n","Já na fusão, a saída final é construída baseada em resultados coletivos, ou seja, nas decisões de todos os preditores heterogêneos para que ao final se tenha uma decisão final, treinando-os em paralelo. São exemplos de métodos de fusão, o comitê Stacking [6]. O Stacking combina as saídas dos classificadores base por meio de um meta classificador para uma predição final, do qual se espera um melhor desempenho. \n","\n","Este relatório tem por objetivo apresentar uma comparação do desempenho de classificadores individuais (Árvore de Decisão e KNN) e da combinação de classificadores (Bagging, Boosting e Stacking), no conjunto de dados, Glass, oriundo do repositório da UCI. O problema analisado é de classificação, no qual, contém: 6 classes, 10 atributos (no total) e 214 instâncias. O objetivo consiste em classificar os tipos de vidros a partir de informações como: índice de refração, quantidades de alumínio, silício, magnésio e outros elementos químicos.\n"]},{"cell_type":"markdown","metadata":{"id":"yrfxNVZZi_vB"},"source":["## **Experimento**"]},{"cell_type":"markdown","metadata":{"id":"pBXbTzqwjV8k"},"source":["Para este experimento, os algoritmos foram implementados na ferramenta Colab, com uso da linguagem Python. O pacote principal utilizado foi o sklearn. "]},{"cell_type":"code","metadata":{"id":"KQ3VLp92igfS"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","#from sklearn.impute import SimpleImputer\n","#from sklearn_pandas import CategoricalImputer\n","from collections import Counter\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import RepeatedKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier # decision tree\n","from sklearn.model_selection import GridSearchCV \n","from sklearn.metrics import classification_report, confusion_matrix \n","from sklearn.neighbors import KNeighborsClassifier # knn\n","from sklearn.svm import SVC # svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import BaggingClassifier, StackingClassifier, AdaBoostClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from imblearn.metrics import geometric_mean_score\n","from copy import copy\n","import warnings\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"7novD8oUihME","executionInfo":{"status":"ok","timestamp":1617149291400,"user_tz":180,"elapsed":1221,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"4d318c6b-4efa-4b0f-c10f-aa8a753fb63c"},"source":["# Carregamento dos dados:\n","cols = ['id','RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'class']\n","df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\", header=None, names=cols)\n","df = df.drop(['id'], axis = 1)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RI</th>\n","      <th>Na</th>\n","      <th>Mg</th>\n","      <th>Al</th>\n","      <th>Si</th>\n","      <th>K</th>\n","      <th>Ca</th>\n","      <th>Ba</th>\n","      <th>Fe</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.52101</td>\n","      <td>13.64</td>\n","      <td>4.49</td>\n","      <td>1.10</td>\n","      <td>71.78</td>\n","      <td>0.06</td>\n","      <td>8.75</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.51761</td>\n","      <td>13.89</td>\n","      <td>3.60</td>\n","      <td>1.36</td>\n","      <td>72.73</td>\n","      <td>0.48</td>\n","      <td>7.83</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.51618</td>\n","      <td>13.53</td>\n","      <td>3.55</td>\n","      <td>1.54</td>\n","      <td>72.99</td>\n","      <td>0.39</td>\n","      <td>7.78</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.51766</td>\n","      <td>13.21</td>\n","      <td>3.69</td>\n","      <td>1.29</td>\n","      <td>72.61</td>\n","      <td>0.57</td>\n","      <td>8.22</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.51742</td>\n","      <td>13.27</td>\n","      <td>3.62</td>\n","      <td>1.24</td>\n","      <td>73.08</td>\n","      <td>0.55</td>\n","      <td>8.07</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>1.51623</td>\n","      <td>14.14</td>\n","      <td>0.00</td>\n","      <td>2.88</td>\n","      <td>72.61</td>\n","      <td>0.08</td>\n","      <td>9.18</td>\n","      <td>1.06</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>1.51685</td>\n","      <td>14.92</td>\n","      <td>0.00</td>\n","      <td>1.99</td>\n","      <td>73.06</td>\n","      <td>0.00</td>\n","      <td>8.40</td>\n","      <td>1.59</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>1.52065</td>\n","      <td>14.36</td>\n","      <td>0.00</td>\n","      <td>2.02</td>\n","      <td>73.42</td>\n","      <td>0.00</td>\n","      <td>8.44</td>\n","      <td>1.64</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>1.51651</td>\n","      <td>14.38</td>\n","      <td>0.00</td>\n","      <td>1.94</td>\n","      <td>73.61</td>\n","      <td>0.00</td>\n","      <td>8.48</td>\n","      <td>1.57</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>213</th>\n","      <td>1.51711</td>\n","      <td>14.23</td>\n","      <td>0.00</td>\n","      <td>2.08</td>\n","      <td>73.36</td>\n","      <td>0.00</td>\n","      <td>8.62</td>\n","      <td>1.67</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>214 rows × 10 columns</p>\n","</div>"],"text/plain":["          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  class\n","0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0      1\n","1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0      1\n","2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0      1\n","3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0      1\n","4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0      1\n","..       ...    ...   ...   ...    ...   ...   ...   ...  ...    ...\n","209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0      7\n","210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0      7\n","211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0      7\n","212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0      7\n","213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0      7\n","\n","[214 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"MdEaia07klSm"},"source":["Este conjunto de dados consiste de valores relativos às proporções de diferentes elementos químos em amostras de vidro. O objetivo é determinar o tipo de vidro (atributo alvo) de uma determinada amostra entre os seguintes:\n","\n","      -- 1 building_windows_float_processed\n","      -- 2 building_windows_non_float_processed\n","      -- 3 vehicle_windows_float_processed\n","      -- 5 containers\n","      -- 6 tableware\n","      -- 7 headlamps\n","\n","A identificação do tipo (e/ou origem) dos fragmentos de vidro tem motivação no campo das investigações criminais, já que, em uma cena de crime, estes fragmentos podem ser usados como evidência se corretamente identificados."]},{"cell_type":"markdown","metadata":{"id":"C0TxKSOmk2jT"},"source":["###**Análise Exploratória dos Dados**"]},{"cell_type":"markdown","metadata":{"id":"vQ0zTXkWk7z7"},"source":["\n","Como primeira etapa do estudo, realizamos uma análise exploratória dos dados com o objetivo de conhecer as principais características do conjunto de dados, como os tipos dos atributos, se há valores faltosos e a correlação entre os atributos e com o atributo alvo (classe). Conforme os resultados obtidos, todos os atributos são numéricos e contínuos, não havendo valores faltosos, corroborando com a descrição dos dados presente no repositório. Três atributos apresentam uma correlação média com o atributo alvo, que é: Na (Sódio), Al (Alumínio) e Ba (Bário). Estes atributos, são portanto, mais importantes para o processo preditivo. Em outras palavras, estes três elementos químicos são decisivos para a determinação das propriedades físicas do vidro que lhe conferem a possibilidade de uso nas suas diferentes aplicações. E foi constatado que em nenhuma das colunas se tem alto grau de correlação, não prejudicando a importância dos atributos."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhGdA7m_WQMa","executionInfo":{"status":"ok","timestamp":1617149291403,"user_tz":180,"elapsed":1211,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"3114af9b-96c6-4b1b-cc15-31d7d436764a"},"source":["#verificar se tem dados faltosos\n","df.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RI       0\n","Na       0\n","Mg       0\n","Al       0\n","Si       0\n","K        0\n","Ca       0\n","Ba       0\n","Fe       0\n","class    0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"sMg6enttlRK_","executionInfo":{"status":"ok","timestamp":1617149291809,"user_tz":180,"elapsed":1600,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"bff9140c-fe74-4821-9755-e7f82d5829b8"},"source":["#correlação\n","df.corr()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RI</th>\n","      <th>Na</th>\n","      <th>Mg</th>\n","      <th>Al</th>\n","      <th>Si</th>\n","      <th>K</th>\n","      <th>Ca</th>\n","      <th>Ba</th>\n","      <th>Fe</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>RI</th>\n","      <td>1.000000</td>\n","      <td>-0.191885</td>\n","      <td>-0.122274</td>\n","      <td>-0.407326</td>\n","      <td>-0.542052</td>\n","      <td>-0.289833</td>\n","      <td>0.810403</td>\n","      <td>-0.000386</td>\n","      <td>0.143010</td>\n","      <td>-0.164237</td>\n","    </tr>\n","    <tr>\n","      <th>Na</th>\n","      <td>-0.191885</td>\n","      <td>1.000000</td>\n","      <td>-0.273732</td>\n","      <td>0.156794</td>\n","      <td>-0.069809</td>\n","      <td>-0.266087</td>\n","      <td>-0.275442</td>\n","      <td>0.326603</td>\n","      <td>-0.241346</td>\n","      <td>0.502898</td>\n","    </tr>\n","    <tr>\n","      <th>Mg</th>\n","      <td>-0.122274</td>\n","      <td>-0.273732</td>\n","      <td>1.000000</td>\n","      <td>-0.481799</td>\n","      <td>-0.165927</td>\n","      <td>0.005396</td>\n","      <td>-0.443750</td>\n","      <td>-0.492262</td>\n","      <td>0.083060</td>\n","      <td>-0.744993</td>\n","    </tr>\n","    <tr>\n","      <th>Al</th>\n","      <td>-0.407326</td>\n","      <td>0.156794</td>\n","      <td>-0.481799</td>\n","      <td>1.000000</td>\n","      <td>-0.005524</td>\n","      <td>0.325958</td>\n","      <td>-0.259592</td>\n","      <td>0.479404</td>\n","      <td>-0.074402</td>\n","      <td>0.598829</td>\n","    </tr>\n","    <tr>\n","      <th>Si</th>\n","      <td>-0.542052</td>\n","      <td>-0.069809</td>\n","      <td>-0.165927</td>\n","      <td>-0.005524</td>\n","      <td>1.000000</td>\n","      <td>-0.193331</td>\n","      <td>-0.208732</td>\n","      <td>-0.102151</td>\n","      <td>-0.094201</td>\n","      <td>0.151565</td>\n","    </tr>\n","    <tr>\n","      <th>K</th>\n","      <td>-0.289833</td>\n","      <td>-0.266087</td>\n","      <td>0.005396</td>\n","      <td>0.325958</td>\n","      <td>-0.193331</td>\n","      <td>1.000000</td>\n","      <td>-0.317836</td>\n","      <td>-0.042618</td>\n","      <td>-0.007719</td>\n","      <td>-0.010054</td>\n","    </tr>\n","    <tr>\n","      <th>Ca</th>\n","      <td>0.810403</td>\n","      <td>-0.275442</td>\n","      <td>-0.443750</td>\n","      <td>-0.259592</td>\n","      <td>-0.208732</td>\n","      <td>-0.317836</td>\n","      <td>1.000000</td>\n","      <td>-0.112841</td>\n","      <td>0.124968</td>\n","      <td>0.000952</td>\n","    </tr>\n","    <tr>\n","      <th>Ba</th>\n","      <td>-0.000386</td>\n","      <td>0.326603</td>\n","      <td>-0.492262</td>\n","      <td>0.479404</td>\n","      <td>-0.102151</td>\n","      <td>-0.042618</td>\n","      <td>-0.112841</td>\n","      <td>1.000000</td>\n","      <td>-0.058692</td>\n","      <td>0.575161</td>\n","    </tr>\n","    <tr>\n","      <th>Fe</th>\n","      <td>0.143010</td>\n","      <td>-0.241346</td>\n","      <td>0.083060</td>\n","      <td>-0.074402</td>\n","      <td>-0.094201</td>\n","      <td>-0.007719</td>\n","      <td>0.124968</td>\n","      <td>-0.058692</td>\n","      <td>1.000000</td>\n","      <td>-0.188278</td>\n","    </tr>\n","    <tr>\n","      <th>class</th>\n","      <td>-0.164237</td>\n","      <td>0.502898</td>\n","      <td>-0.744993</td>\n","      <td>0.598829</td>\n","      <td>0.151565</td>\n","      <td>-0.010054</td>\n","      <td>0.000952</td>\n","      <td>0.575161</td>\n","      <td>-0.188278</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             RI        Na        Mg  ...        Ba        Fe     class\n","RI     1.000000 -0.191885 -0.122274  ... -0.000386  0.143010 -0.164237\n","Na    -0.191885  1.000000 -0.273732  ...  0.326603 -0.241346  0.502898\n","Mg    -0.122274 -0.273732  1.000000  ... -0.492262  0.083060 -0.744993\n","Al    -0.407326  0.156794 -0.481799  ...  0.479404 -0.074402  0.598829\n","Si    -0.542052 -0.069809 -0.165927  ... -0.102151 -0.094201  0.151565\n","K     -0.289833 -0.266087  0.005396  ... -0.042618 -0.007719 -0.010054\n","Ca     0.810403 -0.275442 -0.443750  ... -0.112841  0.124968  0.000952\n","Ba    -0.000386  0.326603 -0.492262  ...  1.000000 -0.058692  0.575161\n","Fe     0.143010 -0.241346  0.083060  ... -0.058692  1.000000 -0.188278\n","class -0.164237  0.502898 -0.744993  ...  0.575161 -0.188278  1.000000\n","\n","[10 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"Re07DsMsjHMp"},"source":["# Separando X e y:\n","X = df[df.columns[:-1]].to_numpy()\n","y = df[df.columns[[-1]]].to_numpy().ravel()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ell85Oygmgla"},"source":["####**Pré-Processamento**"]},{"cell_type":"markdown","metadata":{"id":"PaDiO0dmmnPz"},"source":["As técnicas de pré-processamento visam modificar os dados de entrada para um formato que seja possível realizar análises com um melhor desempenho, que melhorem a qualidade dos dados [6]. Foi verificado o desbalanceamento das classes, no qual, constatou-se que o número de instâncias por classe varia bastante [9,76]. E a partir disso, foi aplicado o SMOTE para realizar o balanceamento das classes, em que criou instâncias sintéticas das classes minoritárias, cada classe ficou com 76 instâncias. Outro fator observado, foi que os atributos estavam em escalas bem diferentes, conforme visto da etapa de análise exploratória. Isso justificou a aplicação de uma técnica de normalização para que ficassem na mesma escala. Adotou-se o min-max, que consiste em colocar os valores numa escala de [0,1]. Para isso, seu cálculo se baseia na função que divide o valor em questão subtraído do menor valor existente e divide esse resultado pela subtração do maior menos o menor valores existentes [7]. Com isso, a escala passa a ser um valor percentual e decimal menor que um. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwnRANQUZ0HO","executionInfo":{"status":"ok","timestamp":1617149291811,"user_tz":180,"elapsed":1588,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"8a838223-2a6d-4268-b4b9-ae56c60a0187"},"source":["# Contagem de instâncias por classe:\n","Counter(df['class'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({1: 70, 2: 76, 3: 17, 5: 13, 6: 9, 7: 29})"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9R45GL0PYfj5","executionInfo":{"status":"ok","timestamp":1617149291811,"user_tz":180,"elapsed":1576,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"4f566ae6-2818-457d-99ea-30c8a840653c"},"source":["X, y = SMOTE().fit_resample(X, y)\n","Counter(y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n","\n","Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n","\n","Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n","\n","Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n","\n","Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n","\n","Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Counter({1: 76, 2: 76, 3: 76, 5: 76, 6: 76, 7: 76})"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"85zhi0ukYu9H"},"source":["# Separando os 5 folds para validação cruzada repetida 2 vezes:\n","rkf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=0)\n","X_train_folds = []\n","y_train_folds = []\n","X_test_folds = []\n","y_test_folds = []\n","for train_index, test_index in rkf.split(X):\n","  X_train_folds.append(X[train_index])\n","  X_test_folds.append(X[test_index])\n","  y_train_folds.append(y[train_index])\n","  y_test_folds.append(y[test_index])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86KIzPxFa32C"},"source":["# Normalização com min-max\n","mm = MinMaxScaler()\n","for i in range(len(X_train_folds)):\n","    X_train_folds[i] = mm.fit_transform(X_train_folds[i])\n","    X_test_folds[i] = mm.transform(X_test_folds[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71JffOE5aHRQ"},"source":["def validacao_cruzada(model):\n","  cv_results = {'test_accuracy':[]}\n","  for fold in range(len(X_train_folds)):\n","      X_train = X_train_folds[fold]\n","      y_train = y_train_folds[fold]\n","      X_test = X_test_folds[fold]\n","      y_test = y_test_folds[fold]\n","      #print('Contagem de classes:\\nTreino = ', Counter(y_train), '\\nTeste: ', Counter(y_test))\n","\n","      model.fit(X_train, y_train)\n","      y_pred = model.predict(X_test)\n","\n","      test_acc = accuracy_score(y_test, y_pred)\n","      cv_results['test_accuracy'].append(test_acc)\n","      test_precision = precision_score(y_test, y_pred)\n","      cv_results['test_precision'].append(test_precision)\n","      test_f1 = f1_score(y_test, y_pred)\n","      cv_results['test_f1'].append(test_f1)\n","  return cv_results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hz0FWFeFO7WZ"},"source":["###**Grid Search**"]},{"cell_type":"markdown","metadata":{"id":"P2CZV-Ecne6U"},"source":["Com o objetivo de estabelecer as melhores escolhas de parâmetros adotados em cada algoritmo de classificação, realizou-se o tuning dos hiperparâmetros por meio da técnica de busca em grade (GridSearch). Para tanto, foi utilizado o pacote *GridSearchCV*.  Os dados foram divididos, de tal forma, que uma parte dos dados de treinamento fossem utilizados para validação e ajustes dos hiperparâmetros. "]},{"cell_type":"code","metadata":{"id":"wTsFa19KPI8P"},"source":["# Separando um conjunto de validação para o GridSearch\n","X_train_all = np.concatenate(X_train_folds)\n","y_train_all = np.concatenate(y_train_folds)\n","rest_X , val_x, rest_y , val_y = train_test_split(X_train_all, y_train_all, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7iPgW4IlHc4"},"source":["####**i) Árvore de Decisão**"]},{"cell_type":"markdown","metadata":{"id":"_uuqmgSPnzAB"},"source":["Foi utilizado o pacote do *sklearn* para implementação de um modelo de árvore de decisão. O ajuste fino compreendeu os seguintes parâmetros: profundidade máxima da árvore e o critério de decisão."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEwKOdwtn7IB","executionInfo":{"status":"ok","timestamp":1617149292095,"user_tz":180,"elapsed":1837,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"f6448a5d-524a-4fc1-fa99-82d514181841"},"source":["decisiontree = DecisionTreeClassifier()\n","criterion = ['gini', 'entropy']\n","max_depth = [2,3,4,6]\n","parameters = dict(criterion=criterion,max_depth=max_depth)\n","dt = GridSearchCV(decisiontree, parameters)\n","dt.fit(val_x, val_y)\n","print('Os melhores parâmetros foram:', dt.best_params_)\n","best_params_criterion = dt.best_params_['criterion']\n","best_params_max_depth = dt.best_params_['max_depth']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Os melhores parâmetros foram: {'criterion': 'entropy', 'max_depth': 6}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tfs6Cj5WRSxs"},"source":["####**ii) K-NN**"]},{"cell_type":"markdown","metadata":{"id":"FZOWh31qn2hF"},"source":["Foi utilizado o pacote do *sklearn* para implementação do algoritmo kNN, o qual está baseado na distância do novo dado considerando-se os k vizinhos. Verificou-se, no ajuste de hiperparâmetros, os melhores valores para *k* e qual a melhor métrica de distância.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SK2kCnIoHxC","executionInfo":{"status":"ok","timestamp":1617149294253,"user_tz":180,"elapsed":3985,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"b06ed560-bf9e-4330-992d-ce5cdd3f5888"},"source":["classifier = KNeighborsClassifier()\n","k_list = list(range(2,31))\n","metric = ['euclidean','minkowski']\n","param_grid= dict(n_neighbors=k_list, metric=metric)\n","knn = GridSearchCV(classifier, param_grid)\n","knn.fit(val_x, val_y)\n","print('Os melhores parâmetros foram:', knn.best_params_)\n","best_n = knn.best_params_['n_neighbors']\n","best_metric = knn.best_params_['metric']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Os melhores parâmetros foram: {'metric': 'euclidean', 'n_neighbors': 2}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"akISvDgIZp3l"},"source":["###**Definindo Funções Auxiliares**"]},{"cell_type":"markdown","metadata":{"id":"kHBDurxonCxk"},"source":["As métricas escolhidas para avaliar a performance de classificação neste estudo são: acurácia (acc), F-Measure (F1), G-mean, precisão (precision) e cobertura (recall).\n"," \n","A métrica da acurácia considera o percentual de acertos dentro do conjunto de dados que está sendo avaliado. A precisão é traduzida pela divisão da quantidade de classificações feitas corretamente pelo total de tentativas que foram positivas. A cobertura corresponde a sensibilidade que é dada pela divisão de casos positivos sobre o total de positivos.\n","A métrica F-Measure envolve tanto a cobertura quanto a precisão, fazendo uma média geométrica entre as duas. \n","A G-mean, por sua vez, pode ser obtida através do cálculo da média geométrica entre as taxas de verdadeiros positivos e de verdadeiros negativos, simbolizando o desempenho do classificador com relação às taxas de acertos das classes. A função abaixo (cros_val) realiza a validação cruzada e calcula as métricas supracitadas para cada fold, armazenado-as em um dicionário que é retornado para posterior análise.\n"]},{"cell_type":"code","metadata":{"id":"ZHEfNsrATy3j"},"source":["def cros_val(X_train_folds, y_train_folds, X_test_folds, y_test_folds, models):\n","    metrics = {'acc':{}, 'f1':{}, 'gmean':{}, 'precision':{}, 'recall':{}}\n","    #Validação cruzada\n","    for name, model in models.items():\n","        print(f'\\nModelo {name}: ')\n","        acc_folds = []\n","        f1_folds = []\n","        gmean_folds = []\n","        precision_folds = []\n","        recall_folds = []\n","        for i in range(len(X_train_folds)):\n","            print('.',end='')\n","            model.fit(X_train_folds[i], y_train_folds[i])\n","            y_pred = model.predict(X_test_folds[i])\n","            y_true = y_test_folds[i]\n","            #Calculando as métricas:\n","            acc_folds.append(accuracy_score(y_true, y_pred))\n","            f1_folds.append(f1_score(y_true, y_pred, average='macro'))\n","            gmean_folds.append(geometric_mean_score(y_true, y_pred, average='macro'))\n","            precision_folds.append(precision_score(y_true, y_pred, average='macro', zero_division=0))\n","            recall_folds.append(recall_score(y_true, y_pred, average='macro'))\n","        metrics['acc'][name] = acc_folds\n","        metrics['f1'][name] = f1_folds\n","        metrics['gmean'][name] = gmean_folds\n","        metrics['precision'][name] = precision_folds\n","        metrics['recall'][name] = recall_folds\n","    return metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W8nPtep0ja2u"},"source":["### **Classificadores monolíticos**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ajxCIfp3oAyx"},"source":["Como dito na introdução do relatório, deseja-se realizar uma comparação do desempenho dos classificadores individuais e da combinação dos classificadores. Dessa forma, são  apresentados a seguir os desempenhos dos classificadores de maneira individual. "]},{"cell_type":"markdown","metadata":{"id":"m2X6kzNcSQgh"},"source":["#### **Definição dos modelos**\n"]},{"cell_type":"code","metadata":{"id":"3PUATj32SU6m"},"source":["mono_models = {'DT':DecisionTreeClassifier(criterion=best_params_criterion, max_depth=best_params_max_depth, random_state=0),\n","               'KNN': KNeighborsClassifier(n_neighbors=best_n, metric=best_metric, n_jobs=-1)\n","              }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a27BTXmJS_1p"},"source":["#### **Validação cruzada e Métricas de Desempenho**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CqGymx2TpZk","executionInfo":{"status":"ok","timestamp":1617149295508,"user_tz":180,"elapsed":5225,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"7994e14c-df83-4eda-eda2-1e5ed971932b"},"source":["#warnings.filterwarnings(action=\"ignore\")\n","warnings.filterwarnings(action=\"default\")\n","metrics_mono = cros_val(X_train_folds, y_train_folds, X_test_folds, y_test_folds, mono_models)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Modelo DT: \n","..........\n","Modelo KNN: \n",".........."],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHRSLv7iTD5J","executionInfo":{"status":"ok","timestamp":1617149295509,"user_tz":180,"elapsed":5216,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"499cc1d6-00f6-4fd2-dd3c-5c2cc6d88e19"},"source":["print('Média das métricas para os modelos:')\n","for name in list(mono_models.keys()):\n","    print(f'*** Modelo {name} ***')\n","    print('Acurácia = ', np.mean(metrics_mono['acc'][name]))\n","    print('F1 = ', np.mean(metrics_mono['f1'][name]))\n","    print('G-Mean = ', np.mean(metrics_mono['gmean'][name]))\n","    print('Precision = ', np.mean(metrics_mono['precision'][name]))\n","    print('Recall = ', np.mean(metrics_mono['recall'][name]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Média das métricas para os modelos:\n","*** Modelo DT ***\n","Acurácia =  0.8322145246058289\n","F1 =  0.83194583598706\n","G-Mean =  0.8994981795109546\n","Precision =  0.8422038676059236\n","Recall =  0.8373568242753194\n","*** Modelo KNN ***\n","Acurácia =  0.8454610606784521\n","F1 =  0.8432168365719459\n","G-Mean =  0.9069585554078834\n","Precision =  0.8551630772286589\n","Recall =  0.8490593255388316\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zh6eYan7VUm6"},"source":["### **Comitês de Classificadores**"]},{"cell_type":"markdown","metadata":{"id":"esx-nNRZoi86"},"source":["Aqui são apresentados os desempenhos da combinação dos classificadores, por meio dos métodos: Bagging, Boosting e Stacking."]},{"cell_type":"markdown","metadata":{"id":"_cuaaPmkvZTk"},"source":["#### **Definição dos modelos**\n","\n"]},{"cell_type":"code","metadata":{"id":"YQmWCKt7l9Fp"},"source":["# Construindo classificadores base:\n","dt_clf = DecisionTreeClassifier(criterion=best_params_criterion, max_depth=best_params_max_depth, random_state=0)\n","knn_clf = KNeighborsClassifier(n_neighbors=best_n, metric=best_metric, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZSbIgP4VfzE"},"source":["#### **Bagging**"]},{"cell_type":"markdown","metadata":{"id":"XwI-INTGo7mq"},"source":["Foi utilizado o pacote do *sklearn* para implementação do Bagging. Obteve-se um modelo considerando como preditores homogêneos a árvore de decisão e outro modelo considerando o KNN."]},{"cell_type":"code","metadata":{"id":"b8uYpbqCVh5r"},"source":["bag_dt_clf = BaggingClassifier(base_estimator=dt_clf, n_estimators=100, n_jobs=-1)\n","bag_knn_clf = BaggingClassifier(base_estimator=knn_clf, n_estimators=100, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMDa_f5OZ536"},"source":["#### **Boosting**"]},{"cell_type":"markdown","metadata":{"id":"IhR-rZ4fo_7U"},"source":["Foi utilizado o pacote do *sklearn* para implementação do Boosting, no qual, utilizou-se o algoritmo: Adaboost. Obteve-se um comitê considerando como preditores homogêneos a árvore de decisão. Não foi possível obter um comitê com o KNN como modelo base pois o KNN não suporta ponderação de amostras, algo que é fundamental para o funcionamento de uma algoritmo de Boosting."]},{"cell_type":"code","metadata":{"id":"HyZ1qK1JgX-u"},"source":["adaboost_dt_clf = AdaBoostClassifier(base_estimator=dt_clf, n_estimators=100)\n","#Para o adaboost, usamos somente as DTs, pois não é possível aplicar boosting ao KNN, já que não suporta sample_weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4D4mVMcWrIW"},"source":["#### **Stacking**"]},{"cell_type":"markdown","metadata":{"id":"61ZMlxItpJBJ"},"source":["Foi utilizado o pacote do *sklearn* para implementação do Stacking. Como meta-classificador fez uso da regressão logística. Obteve-se um comitê homogêneo com uso de árvore de decisão como modelo base, outro homogêneo com uso do KNN como base e um comitê híbrido, composto por 50% de modelos de árvores de decisão e 50% de modelos KNN. "]},{"cell_type":"code","metadata":{"id":"kKXRr6BpWwge"},"source":["# A classe StackingClassifier pede que passemos os classificadores que irão compor o pool em tuplas com os nomes. \n","# Para realizarmos uma comparação justa, utilizaremos o mesmo pool gerado pelo bagging.\n","# Para isso, precisamos dar o fit() no Bagging para que sejam criados os 100 estimadores. \n","# Durante a cros_val, o fit será refeito com os folds.\n","\n","bag_dt_clf.fit(X,y)\n","bag_knn_clf.fit(X,y);\n","\n","bag_dt_named_pool = {(f'dt_{i}', bag_dt_clf.estimators_[i]) for i in range(bag_dt_clf.n_estimators)}\n","bag_knn_named_pool = {(f'knn_{i}', bag_knn_clf.estimators_[i]) for i in range(bag_knn_clf.n_estimators)}\n","\n","#Construindo um pool híbrido:\n","bag_hib_named_pool = random.sample(bag_dt_named_pool, int(0.5*bag_dt_clf.n_estimators)) + random.sample(bag_knn_named_pool, int(0.5*bag_knn_clf.n_estimators))\n","\n","lr = LogisticRegression(max_iter=200, tol=1e-3, n_jobs=-1)\n","stack_dt_clf = StackingClassifier(estimators=bag_dt_named_pool, final_estimator=lr, n_jobs=-1)\n","stack_knn_clf = StackingClassifier(estimators=bag_knn_named_pool, final_estimator=lr, n_jobs=-1)\n","stack_hib_clf = StackingClassifier(estimators=bag_hib_named_pool, final_estimator=lr, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkZsntUQvm0W"},"source":["ens_models = {'Bagging - DT': bag_dt_clf,\n","              'Bagging - KNN': bag_knn_clf,\n","              'AdaBoost - DT': adaboost_dt_clf, \n","              'Stacking - DT': stack_dt_clf,\n","              'Stacking - KNN': stack_knn_clf,\n","              'Stacking - Híbrido': stack_hib_clf\n","             }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ebfz6VNhve7f"},"source":["#### **Validação cruzada e Métricas de Desempenho**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAWXnOtmu5B2","executionInfo":{"status":"ok","timestamp":1617149752110,"user_tz":180,"elapsed":404631,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"81a6bbb2-48df-421b-fd15-976bca0ae9c9"},"source":["metrics_ens = cros_val(X_train_folds, y_train_folds, X_test_folds, y_test_folds, ens_models)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Modelo Bagging - DT: \n","..........\n","Modelo Bagging - KNN: \n","..........\n","Modelo AdaBoost - DT: \n","..........\n","Modelo Stacking - DT: \n","..........\n","Modelo Stacking - KNN: \n","..........\n","Modelo Stacking - Híbrido: \n",".........."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axyykpFpwugw"},"source":["print('Média das métricas para os modelos de ensemble:')\n","for name in list(ens_models.keys()):\n","    print(f'*** Modelo {name} ***')\n","    print('Acurácia = ', np.mean(metrics_ens['acc'][name]))\n","    print('F1 = ', np.mean(metrics_ens['f1'][name]))\n","    print('G-Mean = ', np.mean(metrics_ens['gmean'][name]))\n","    print('Precision = ', np.mean(metrics_ens['precision'][name]))\n","    print('Recall = ', np.mean(metrics_ens['recall'][name]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-hE_Fxj_bTC"},"source":["### **Resultados e Discussões**"]},{"cell_type":"markdown","metadata":{"id":"od2yPaJArolc"},"source":["A seguir são apresentadas, em um gráfico de barras, a performance dos classificadores em termos das métricas avaliadas.\n"," "]},{"cell_type":"code","metadata":{"id":"xmj4WZVR_fmH"},"source":["def plot_metrics(metrics):\n","    labels = list(metrics['acc'].keys()) #Nomes dos modelos\n","    \n","    acc_means = [np.mean(l) for l in list(metrics['acc'].values())]\n","    f1_means = [np.mean(l) for l in list(metrics['f1'].values())]\n","    gmean_means = [np.mean(l) for l in list(metrics['gmean'].values())]\n","    prec_means = [np.mean(l) for l in list(metrics['precision'].values())]\n","    rec_means = [np.mean(l) for l in list(metrics['recall'].values())]\n","   \n","    x = np.arange(len(labels)) # Os locais dos labels no eixo x\n","    width = 0.16 # largura das barras\n","    fig, ax = plt.subplots(figsize=(16,10))\n","    #TODO: Consertar posições das barras!\n","    rects_acc = ax.bar(x - 2*width, acc_means, width, label='Acurácia')\n","    rects_precision = ax.bar(x - width, prec_means, width, label='Precisão')\n","    rects_recall = ax.bar(x , rec_means, width, label='Cobertura')\n","    rects_f1 = ax.bar(x  + width, f1_means, width, label='F-measure')\n","    rects_gmean = ax.bar(x + 2*width, gmean_means, width, label='G-Mean')\n","    ax.set_ylabel('Performance')\n","    #ax.set_title('Performance por modelo')\n","    ax.set_xticks(x)\n","    ax.set_xticklabels(labels)\n","    ax.set_ylim([0,1])\n","    plt.grid(True)\n","    ax.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOJF0Ep4rzrY"},"source":["#### Gráficos de Barras\n","\n","Os gráficos abaixo mostram as médias das métricas para cada modelo."]},{"cell_type":"code","metadata":{"id":"tzUUITrz_hLS","colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"ok","timestamp":1617150177864,"user_tz":180,"elapsed":1260,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"47d0e065-a92d-4540-81b5-9b9f2aea5ba1"},"source":["# Juntando as métricas dos modelos mono e ensemble para um único plot:\n","metrics_all = {}\n","for m in list(metrics_mono.keys()):\n","  metrics_all[m] = copy(metrics_mono[m])\n","  metrics_all[m].update(metrics_ens[m])\n","\n","plot_metrics(metrics_all)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1152x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"4SWAbW4fTC20","executionInfo":{"status":"ok","timestamp":1617150274835,"user_tz":180,"elapsed":712,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"740b6298-cafc-4a08-bfd9-a37950efe621"},"source":["import plotly.graph_objects as go\n","categories = ['DT','KNN','Bagging - DT', 'Bagging - KNN', 'AdaBoost - DT','Stacking - DT',\n","              'Stacking - KNN','Stacking - Híbrido']\n","\n","acc_means = [np.mean(l) for l in list(metrics_all['acc'].values())]\n","f1_means = [np.mean(l) for l in list(metrics_all['f1'].values())]\n","gmean_means = [np.mean(l) for l in list(metrics_all['gmean'].values())]\n","prec_means = [np.mean(l) for l in list(metrics_all['precision'].values())]\n","rec_means = [np.mean(l) for l in list(metrics_all['recall'].values())]\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatterpolar(r=acc_means,theta=categories,fill='toself',name='Acurácia'))\n","fig.add_trace(go.Scatterpolar(r=f1_means,theta=categories,fill='toself',name='F-Measure'))\n","fig.add_trace(go.Scatterpolar(r=gmean_means, theta=categories,fill='toself',name='G-Mean'))\n","fig.add_trace(go.Scatterpolar(r=prec_means,theta=categories,fill='toself',name='Precisão'))\n","fig.add_trace(go.Scatterpolar(r=rec_means, theta=categories,fill='toself',name='Cobertura')),\n","fig.update_layout(polar=dict(radialaxis=dict(visible=True,range=[0.82, 1])),showlegend=False)\n","\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"31ba421f-a6ab-404e-acc0-8f57f16cb514\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"31ba421f-a6ab-404e-acc0-8f57f16cb514\")) {\n","                    Plotly.newPlot(\n","                        '31ba421f-a6ab-404e-acc0-8f57f16cb514',\n","                        [{\"fill\": \"toself\", \"name\": \"Acur\\u00e1cia\", \"r\": [0.8322145246058289, 0.8454610606784521, 0.8706163401815574, 0.8618967988533207, 0.9232441471571906, 0.8311634018155758, 0.855315336837076, 0.8662804586717631], \"theta\": [\"DT\", \"KNN\", \"Bagging - DT\", \"Bagging - KNN\", \"AdaBoost - DT\", \"Stacking - DT\", \"Stacking - KNN\", \"Stacking - H\\u00edbrido\"], \"type\": \"scatterpolar\"}, {\"fill\": \"toself\", \"name\": \"F-Measure\", \"r\": [0.83194583598706, 0.8432168365719459, 0.8696335867202866, 0.8563933731336622, 0.9219674815874909, 0.8300183767713211, 0.854499043373731, 0.8650212089354822], \"theta\": [\"DT\", \"KNN\", \"Bagging - DT\", \"Bagging - KNN\", \"AdaBoost - DT\", \"Stacking - DT\", \"Stacking - KNN\", \"Stacking - H\\u00edbrido\"], \"type\": \"scatterpolar\"}, {\"fill\": \"toself\", \"name\": \"G-Mean\", \"r\": [0.8994981795109546, 0.9069585554078834, 0.9225471550817674, 0.9159206961161507, 0.9544828486104636, 0.8986691227436223, 0.9139248093782812, 0.9199199342430667], \"theta\": [\"DT\", \"KNN\", \"Bagging - DT\", \"Bagging - KNN\", \"AdaBoost - DT\", \"Stacking - DT\", \"Stacking - KNN\", \"Stacking - H\\u00edbrido\"], \"type\": \"scatterpolar\"}, {\"fill\": \"toself\", \"name\": \"Precis\\u00e3o\", \"r\": [0.8422038676059236, 0.8551630772286589, 0.8725754795027241, 0.8642665584201008, 0.9232510804898576, 0.8460003258614275, 0.8574711047752842, 0.868408668024251], \"theta\": [\"DT\", \"KNN\", \"Bagging - DT\", \"Bagging - KNN\", \"AdaBoost - DT\", \"Stacking - DT\", \"Stacking - KNN\", \"Stacking - H\\u00edbrido\"], \"type\": \"scatterpolar\"}, {\"fill\": \"toself\", \"name\": \"Cobertura\", \"r\": [0.8373568242753194, 0.8490593255388316, 0.8739315367326371, 0.8630179143213367, 0.9253483235635107, 0.8360492633721701, 0.8601759858430507, 0.8696009920230878], \"theta\": [\"DT\", \"KNN\", \"Bagging - DT\", \"Bagging - KNN\", \"AdaBoost - DT\", \"Stacking - DT\", \"Stacking - KNN\", \"Stacking - H\\u00edbrido\"], \"type\": \"scatterpolar\"}],\n","                        {\"polar\": {\"radialaxis\": {\"range\": [0.82, 1], \"visible\": true}}, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('31ba421f-a6ab-404e-acc0-8f57f16cb514');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mZrXvW6qZqcG"},"source":["Observando os dois gráficos acima, destacamos os seguintes pontos:\n","\n","*   O Melhor comitê, considerando as cinco métricas, foi aquele construído com o AdaBoost tendo como modelos base as árvores de decisão (DT). \n","*   Para os ensembles construídos com Bagging, o melhor modelo base, para todas as métricas, foi o de árvore de decisão (DT). Este achado explica-se pelo fato destes modelos de árvore de decisão terem mais alta variância e serem altamente sensíveis a mudanças nos dados apresentados (tal qual as subamostragens feitas no Bagging) sendo portanto considerados aprendizes fracos, o que possibilita a construção de um pool com alta diversidade. \n","*   Também para todas as métricas, os modelos de ensemble com Bagging e Adaboost superaram os dois modelos monolíticos DT e KNN. Somente o modelo de ensemble com Stacking e DT como modelo base apresentou métricas inferiores aos modelos monolíticos.\n","*   Para o caso do algoritmo de Stacking, a construção de um pool híbrido permitiu o aumento da performance se comparado ao mesmo algoritmo quando considerado os pools homogêneos (DT ou KNN), indicando que este algoritmo funciona melhor com pools heterogêneos.\n","\n","\n","É salutar no entanto que seja verificada a significância estatística dessas diferenças. Na seção seguinte realizaremos um teste de hipótese com este fim.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C_hpUExcvmJT"},"source":["#### Teste de Hipótese\n","\n","Para a realizaçao desta etapa, foi necessario que antes fosse feito um teste de aderência de forma a identificar se o comportamento dos dados se assemelhava a uma distribuiçao normal. Foi aplicado o teste de Shapiro-Wilk. Em seguida, mediante o resultado do teste, seguiu-se com o teste de hipotese. Foram consideradas as seguintes hipóteses:\n","\n","$𝐻_0$  - Não há diferença significativa entre a perfomance dos modelos monolíticos e os modelos de ensemble.\n","\n","$𝐻_1$  - Há diferença significativa entre a perfomance dos modelos monolíticos e os modelos de ensemble.\n","\n"]},{"cell_type":"code","metadata":{"id":"GEyrs-eqvoX8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617150895488,"user_tz":180,"elapsed":681,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"4bbaeefc-1a4b-4f2d-bbc6-4a37fabc823c"},"source":["# Primeiramente é necessário realizar um teste de aderência, para vericar a normalidade dos dados:\n","import scipy.stats as stats\n","# Teste de normalidade \n","def teste_shapiro(data):\n","  shapiro_stat, shapiro_p_valor=stats.shapiro(data)\n","  #print('O valor da estatistica de Shapiro-Wilk =%.3f, O valor de p de Shapiro-Wilk=%.3f' % (shapiro_stat, shapiro_p_valor))\n","  alpha = 0.05\n","  return shapiro_p_valor <= alpha\n","\n","for model in list(metrics_all['acc'].keys()): #Nome dos modelos\n","  print(f'\\n** {model} **')\n","  nenhum_rejeita = True\n","  for metric in ['acc', 'recall','precision', 'f1', 'gmean']:\n","    #print(f'- Métrica: {metric}')\n","    if teste_shapiro(metrics_all[metric][model]):\n","      print(f'A amostra do modelo {model} com a métrica {metric} não se assemelha a uma Gaussiana (rejeita H0)')\n","      nenhum_rejeita = False\n","  if nenhum_rejeita: print('Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)')\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","** DT **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n","\n","** KNN **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n","\n","** Bagging - DT **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n","\n","** Bagging - KNN **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n","\n","** AdaBoost - DT **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n","\n","** Stacking - DT **\n","A amostra do modelo Stacking - DT com a métrica precision não se assemelha a uma Gaussiana (rejeita H0)\n","\n","** Stacking - KNN **\n","A amostra do modelo Stacking - KNN com a métrica acc não se assemelha a uma Gaussiana (rejeita H0)\n","A amostra do modelo Stacking - KNN com a métrica precision não se assemelha a uma Gaussiana (rejeita H0)\n","\n","** Stacking - Híbrido **\n","Para este modelo todas as amostras se assemelham a uma Gaussiana (não rejeitam H0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mMo7GYRoi1fE"},"source":["Como no resultado do teste, nem todas as amostras apresentam uma distribuição normal, portanto adotou-se como teste de hipótese não paramétrico. Foi aplicado o teste *Wilcoxon* para verificar o desempenho dos classificadores."]},{"cell_type":"code","metadata":{"id":"3fH5sIUo-wn9"},"source":["# Teste de Hipotese \n","def teste_w(x1, x2):\n","  from scipy.stats import wilcoxon\n","  stat, p = wilcoxon(x1, x2) \n","  print('O valor da estatistica =%.3f,  O valor de p =%.3f' % (stat, p))\n","  if p > 0.05: \n","        print('A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)')\n","  else:\n","        print('A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHOAHd1mA1nL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617150901119,"user_tz":180,"elapsed":1011,"user":{"displayName":"Sara Coutinho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOauIe_K9J76dZIrinJ65cIDcXn48cyYGkcPVw=s64","userId":"01315780585839170990"}},"outputId":"08d0f72b-6505-4248-c4af-0c8daed58a32"},"source":["for model_mono in list(mono_models.keys()):\n","  for model_ens in list(ens_models.keys()): #Nome dos modelos\n","    print(f'\\n** Comparando {model_mono} vs. {model_ens} **')\n","    for metric in ['acc', 'recall','precision', 'f1', 'gmean']:\n","      print(f'- Métrica: {metric}')\n","      teste_w(metrics_mono[metric][model_mono], metrics_ens[metric][model_ens])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","** Comparando DT vs. Bagging - DT **\n","- Métrica: acc\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =2.000,  O valor de p =0.009\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","\n","** Comparando DT vs. Bagging - KNN **\n","- Métrica: acc\n","O valor da estatistica =11.000,  O valor de p =0.092\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =12.000,  O valor de p =0.114\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =14.000,  O valor de p =0.169\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =14.000,  O valor de p =0.169\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =12.000,  O valor de p =0.114\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando DT vs. AdaBoost - DT **\n","- Métrica: acc\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","\n","** Comparando DT vs. Stacking - DT **\n","- Métrica: acc\n","O valor da estatistica =13.500,  O valor de p =0.933\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =12.000,  O valor de p =0.735\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =18.000,  O valor de p =0.594\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =21.000,  O valor de p =0.859\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =17.000,  O valor de p =0.889\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando DT vs. Stacking - KNN **\n","- Métrica: acc\n","O valor da estatistica =9.000,  O valor de p =0.059\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =9.000,  O valor de p =0.059\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =15.000,  O valor de p =0.203\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =10.000,  O valor de p =0.074\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =9.000,  O valor de p =0.059\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando DT vs. Stacking - Híbrido **\n","- Métrica: acc\n","O valor da estatistica =2.500,  O valor de p =0.011\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =5.000,  O valor de p =0.022\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =4.000,  O valor de p =0.017\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =3.000,  O valor de p =0.013\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =5.000,  O valor de p =0.022\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","\n","** Comparando KNN vs. Bagging - DT **\n","- Métrica: acc\n","O valor da estatistica =8.000,  O valor de p =0.085\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =11.000,  O valor de p =0.093\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =16.000,  O valor de p =0.241\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =9.000,  O valor de p =0.059\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =11.000,  O valor de p =0.093\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando KNN vs. Bagging - KNN **\n","- Métrica: acc\n","O valor da estatistica =6.000,  O valor de p =0.092\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =11.000,  O valor de p =0.093\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =17.000,  O valor de p =0.285\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =12.000,  O valor de p =0.114\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =10.000,  O valor de p =0.074\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando KNN vs. AdaBoost - DT **\n","- Métrica: acc\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =0.000,  O valor de p =0.005\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","\n","** Comparando KNN vs. Stacking - DT **\n","- Métrica: acc\n","O valor da estatistica =8.000,  O valor de p =0.160\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =17.000,  O valor de p =0.285\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =25.000,  O valor de p =0.799\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =17.000,  O valor de p =0.285\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =16.000,  O valor de p =0.241\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando KNN vs. Stacking - KNN **\n","- Métrica: acc\n","O valor da estatistica =6.500,  O valor de p =0.204\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =8.000,  O valor de p =0.161\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =18.000,  O valor de p =0.594\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =10.000,  O valor de p =0.139\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =8.000,  O valor de p =0.161\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","\n","** Comparando KNN vs. Stacking - Híbrido **\n","- Métrica: acc\n","O valor da estatistica =4.500,  O valor de p =0.033\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: recall\n","O valor da estatistica =3.000,  O valor de p =0.013\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: precision\n","O valor da estatistica =12.000,  O valor de p =0.114\n","A diferença entre as médias das métricas não é estatisticamente significante (não rejeita H0)\n","- Métrica: f1\n","O valor da estatistica =5.000,  O valor de p =0.022\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n","- Métrica: gmean\n","O valor da estatistica =3.000,  O valor de p =0.013\n","A diferença entre as médias das métricas é estatisticamente significante (rejeita H0)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/scipy/stats/morestats.py:2879: UserWarning:\n","\n","Sample size too small for normal approximation.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Q4mv3U8OvcVx"},"source":["Em relação a métrica de **Acurácia**, os modelos que rejeitaram $H_0$ foi em relação ao Bagging - DT (DT e KNN) e ao AdaBoost - DT (DT e KNN). Assim, a diferença entre as médias é estatisticamente significante. Os demais modelos aceitaram $H_0$, concluindo que a diferença entre as médias não é estatisticamente significante. \n","\n","Em relação a métrica de **F-Measure**, os modelos que rejeitaram $H_0$ foi em relação ao Bagging - DT (DT e KNN) e AdaBoost - DT (DT e KNN). Assim, a diferença entre as médias é estatisticamente significante. Os demais modelos aceitaram $H_0$, concluindo que a diferença entre as médias não é estatisticamente significante. \n","\n","\n","Em relação a métrica de **Recall**, os modelos que rejeitaram $H_0$ foram em relação ao Bagging DT (DT e KNN), AdaBoost - DT (DT e KNN) e Stacking - KNN (KNN). Assim, a diferença entre as médias é estatisticamente significante. Os demais modelos aceitaram $H_0$, concluindo que a diferença entre as médias não é estatisticamente significante. \n","\n","Em relação a métrica de **Precision**,  os modelos que rejeitaram $H_0$ foi em relação ao Bagging - DT (DT) e ao AdaBoost - DT (DT e KNN). Assim, a diferença entre as médias é estatisticamente significante. Os demais modelos aceitaram $H_0$, concluindo que a diferença entre as médias não é estatisticamente significante. \n","\n","Em relação a métrica de **G-Mean**, os modelos que rejeitaram $H_0$ foi em relação ao Bagging DT (DT e KNN), AdaBoost - DT (DT e KNN) e Stacking - KNN (KNN). Assim, a diferença entre as médias é estatisticamente significante. Os demais modelos aceitaram $H_0$, concluindo que a diferença entre as médias não é estatisticamente significante. "]},{"cell_type":"markdown","metadata":{"id":"owRymE8QpqbN"},"source":["###**Conclusão**"]},{"cell_type":"markdown","metadata":{"id":"Th2CRdAivnTj"},"source":["A proposta do trabalho foi fazer um estudo comparativo entre o desempenho de classificadores individuais e classificadores combinados (comitês) estudando a performance de classificação para o conjunto de dados Glass, sobre tipos de vidro e suas composições. Foram adotados os classificadores individuais: Árvore de Decisão e KNN. Já os métodos de combinação foram: Bagging, Boosting e Stacking. \n"," \n","Antes da execução dos modelos, o conjunto de dados foi normalizado e foi aplicada uma técnica de pré-processamento para tratar o desbalanceamento das classes, no qual fez uso do SMOTE. As métricas utilizadas para avaliação do desempenho foram: Acurácia, F-Measure, Precisão, Cobertura e G-mean. Foi utilizada uma validação cruzada de cinco folds em duas repetições e fez-se uso de busca em grade para ajuste dos hiperparâmetros dos modelos individuais, considerando uma parte do conjunto de treino para validação.\n","\n","A partir dos resultados, o comitê que apresentou um desempenho superior aos demais, em relação às cinco métricas analisadas, foi o AdaBoost tendo como modelo base as Árvores de Decisão (DT). O melhor modelo base, também em relação às todas as métricas para a construção dos comitês Bagging, foi a DT, isso pode ser explicado em decorrência da sensibilidade às mudanças nos dados e alta variância do modelo DT. Os modelos Bagging e Adaboost superaram os dois modelos individuais DT e KNN. Para o algoritmo Stacking, a construção de um pool híbrido (DT e KNN) permitiu um aumento no desempenho em comparação ao seu uso considerando os pools homogêneos (DT ou KNN), indicando que esse comitê apresenta um melhor desempenho final quando utiliza preditores heterogêneos. \n","\n","Em seguida, aplicou-se um teste de hipótese, com nível de significância de 0.05, para comparação dos modelos individuais com os comitês de classificadores, em que para as métricas de **Acurácia** e **F-Measure**, conclui-se que em relação aos modelos individuais: DT e KNN, os comitês: Bagging - DT e AdaBoost - DT, apresentaram diferença significativa entre as médias, os demais não apresentaram essa diferença significativa. Em relação a métrica **Recall** e **G-Mean**, pode-se concluir que os comitês: Bagging - DT e AdaBoost - DT, com os modelos individuais: DT e KNN e o comitê Stacking - KNN com o modelo individual: KNN, apresentaram diferença significativa entre as médias, os demais não apresentaram essa diferença significativa. Já em relação a métrica de **Precisão**, o Bagging - DT com o modelo individual: DT e o AdaBoost - DT com: DT e KNN, apresentaram diferença entre as médias estatisticamente significativas, os demais modelos não apresentaram essa diferença.\n","\n","Por fim, verificamos que o uso de comitês de classificadores é capaz de promover o aumento da performance em relação ao modelo base utilizado no comitê (vide DT vs. Adaboost), mas é importante salientar que nem sempre isso ocorre (vide DT vs. Stacking DT) e mesmo quando ocorre, a diferença de performance nem sempre é suficiente (ou significante) para justificar o aumento do custo computacional em que se incorre (vide KNN vs. Bagging KNN). Toda aplicação de uma metodologia mais complexa deve ser fundamentada numa cuidadosa análise de custos vs. benefícios, e não é diferente com os métodos de comitês de classificadores.\n"]},{"cell_type":"markdown","metadata":{"id":"qVT2UWHmFE3r"},"source":["##**Referências**"]},{"cell_type":"markdown","metadata":{"id":"9RO_oHf2FHNV"},"source":["[1] KUNCHEVA, L. I. Combining Pattern Classifiers: Methods and Algorithms.\n","Wiley-Interscience, 2004. ISBN 0471210781,9780471210788. Disponível em: <http: //gen.lib.rus.ec/book/index.php md5=D3E45AB795C1549CFC5A3374FEA50373>.\n","\n","[2] SILVA, W. K. N. d. Construções de comitês de classificadores multirrótulos no aprendizado\n","semissupervisionado multidescrição. Universidade Federal Rural do Semi-Árido, 2017.\n","\n","[3] BREIMAN, L. Bagging predictors. Machine learning, Springer, v. 24, n. 2, p. 123–140, 1996.\n","\n","[4] SCHAPIRE, R. E. The strength of weak learnability. Machine learning, Springer, v. 5,\n","n. 2, p. 197–227, 1990.\n","\n","[5] CARDEAL, Enzo et al. Modelos de Predição | Ensemble Learning. 2021. Disponível em: https://medium.com/turing-talks/turing-talks-24-modelos-de-predi%C3%A7%C3%A3o-ensemble-learning-aa02ce01afda. Acesso em: 28 mar. 2021.\n","\n","[6] WOLPERT, D. H. Stacked generalization. Neural networks, Elsevier, v. 5, n. 2, p. 241–259,\n","1992."]}]}